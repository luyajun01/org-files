# -*- org-confirm-babel-evaluate: nil; -*-
#+PROPERTY: header-args :eval never-export
#+TITLE: 统计 wiki
#+OPTIONS: num:3 H:4 ^:nil pri:t
#+HTML_HEAD: <link  href="https://rawgithub.com/luyajun01/code/master/css/org-css.css" rel="stylesheet" type="text/css">
#+LATEX_HEADER: \bibliography{references.bib}

  - [[wiki:index][Index]]

  - Related: [[wiki:R_WIKi][R]]

知识需要定期复习！

 #+BEGIN_SRC quote
如果你对数据绝对没有任何假设，那么你没有理由会更偏好于某个模型。  —— “没有免费午餐定理”

有时，发现问题，比解决问题更困难。

学而不思则罔！

如何思？请用最精炼的语言总结学习的内容。
 #+END_SRC

思考的几个层次：

1.用最凝练的语言总结学习的内容。

3.思维需要发散。

4.尽量自己发现问题。

* 统计学
** 问题

| 模型                | 参数估计 | 优点 | 不足 | 分类/聚类/回归 |
| logistic            |          |      |      |                |
| stepwise regression |          |      |      |                |
| naive bayes         |          |      |      |                |
| gbdt                |          |      |      |                |
| xgboost             |          |      |      |                |
| lightgbm            |          |      |      |                |
| CNN                 |          |      |      |                |
| svm                 |          |      |      |                |
| PCA                 |          |      |      |                |

- stepwise regression

是一种变量选择模型。标准的逐步回归做两件事，每一步中增加或移除自变量。向前选择从模型中最重要的自变量开始，然后每一步中增加变量。向后选择从模型所有的自变量开始，然后每一步中移除最小显著变量。

- xgboost

首先，xgboost 是梯度提升家族一员。如果是二分类问题的话，其背后的算法思想可以等价于 additive logistic model,这个问题 Frediman 已经证明了，严格地说，xgboost 在做
二分类问题时就相当于做 带有惩罚项的 additive logistic model。

- PCA

是一种降维方法，其思想就是利用一种变换将原始特征正交化，变换后的特征之间独立，其背后就是思想就是计算 X 的协方差矩阵，然后取其前 K 个特征向量组成新的特征矩阵，从
而完成数据降维的目的。

- naive bayes

是基于贝叶斯定理与特征条件独立假设的分类方法。首先基于特征条件独立假设学习输入、输出的联合概率分布；然后基于此模型，对给定的输入 x, 利用贝叶斯定理求出后验概率最大的输出 y.

- svm

是一种二分类模型，定义在特征空间上的间隔最大的线性分类器，核技巧使它成为实质上的非线性分类器。支持向量机的学习策略就是间隔最大化，等价于求解凸二次规划的问题。

核方法的基本思想是通过一个非线性变换，把输入数据映射到高维的希尔伯特空间中，在这个高维空间里，那些在原始输入空间中线性不可分的问题变得更加容易解决，甚至线性可分。

- knn

和 K-means 不同，KNN 是有监督学习模型，算法大体思路是一个样本与特征空间中的 K 样本最相似，那么就和这 K 个样本中大多数类一样。

- kmeans

无监督学习，是聚类算法。选择 k 个样本确定初始聚类中心，针对每个样本计算到 k 个聚类中心的距离，并将这个样本分到距离最小的聚类中心对应的类中；重新计算它的聚类中心；
重复上面操作；直到每个样本对应类结果不发生变化。
** 统计学习三要素

模型、策略、算法

- 模型：参数模型、非参数模型、半参数模型

- 策略：按照什么样的学习策略去求解模型参数。0-1 损失，平方损失，绝对损失，对数损失等。

具体地讲，损失函数值越小，模型越好，由于模型的输入、输出 $(X,Y)$ 是随机变量，遵循联合分布 $P(X,Y)$, 所以损失函数的期望是

\begin{equation}
R_{\mathrm{exp}}(f)=E_{P}[L(Y, f(X))]=\int_{\chi \times \nu} L(y, f(x)) P(x, y) \mathrm{d} x \mathrm{~d} y
\end{equation}

这是理论上模型 $f(X)$ 关于联合分布 $P(X,Y)$ 的平均意义下的损失，称为风险函数或期望损失。

但是，期望损失无法求解，因为联合分布在实际生活中无法知道，所以，引入经验风险损失。

给定一个训练数据集，

$$
T=\left\{\left(x_{1}, y_{1}\right),\left(x_{2}, y_{2}\right), \cdots,\left(x_{N}, y_{N}\right)\right\}
$$

模型 $f(X)$ 关于训练数据集的平均损失称为经验风险损失，记作 $R_{emp}$

$$
R_{\mathrm{emp}}(f)=\frac{1}{N} \sum_{i=1}^{N} L\left(y_{i}, f\left(x_{i}\right)\right)
$$

期望风险 $R_{exp}(f)$ 是模型关于联合分布的期望损失，经验风险 $R_{emp}(f)$ 是模型关于训练样本集的平均损失。理论上说，当样本容量 $N$ 趋于无穷时，经验风险 $R_{emp}(f)$ 趋于期望风险 $R_{exp}(f)$, 所以一个自然的想法是用经验风险估计期望风险。但是，实际中训练样本数目有限，所以，用经验风险估计期望风险常常不理想，所以需要对经验风险进行一定的矫正。这就关系到监督学习的两个策略：经验风险最小化和结构风险最小化，前者即是常见的损失函数求 min, 后者是加惩罚。

- 算法

如何求解损失函数，这里会有很多算法。

** 数学基础
** 标量\向量\矩阵\张量
** 2 概率论
*** 贝叶斯定理

贝叶斯公式的一般形式如：$P(A | B)=\frac{P(A \cap B)}{P(B)}$,更为一般的形式为$P\left(A_{i} | B\right)=\frac{P\left(B | A_{i}\right) P\left(A_{i}\right)}{\sum_{j} P\left(B | A_{j}\right) P\left(A_{j}\right)}$.
如何证明？

不妨假设，在事件 B 发生的条件下事件 A 发生的概率是：

$P(A | B)=\frac{P(A \cap B)}{P(B)}$.

同样，在事件 A 发生的条件下事件 B 发生的概率$P(B | A)=\frac{P(A \cap B)}{P(A)}$.
整合上述两式，可得：$P(A | B) P(B)=P(A \cap B)=P(B | A) P(A)$,容易得到贝叶斯定理。

*** 收敛理论

依概率收敛：
\begin{equation}
 \lim _{n \rightarrow \infty} p\left(\left|x_{n}-x\right| \geqslant \varepsilon\right)=0 \quad x_{n} \stackrel{p}{\rightarrow} x
\end{equation}
以概率 1 收敛：
\begin{equation}
 P\left(\lim_{n \rightarrow \infty} X_{n}=X\right)=1 \quad x_{n} \stackrel{\text { a.s. }}{\rightarrow} X
\end{equation}

依分布收敛：
\begin{equation}
 \lim _{n \rightarrow \infty} p\left(x_{n} \leqslant x\right)=P(X \leqslant x) \quad X_{n} \stackrel{d}{\rightarrow} x
\end{equation}

可以证明依概率收敛可以推出依分布收敛。

** 3 统计理论
*** 期望和均值区别
均值针对的是实验观察到的特征样本而言。

期望是针对随机变量而言的一个量，可以理解是一种站在“上帝视角”的值。均值是一个统计量（对观察样本的统计），期望是一种概率论，是一个数学特征。

可以看出期望是与概率值联系在一起的，如果说概率是频率随样本趋于无穷的极限，期望就是平均数随样本趋于无穷的极限，可以看出均值和期望的联系也是大数定理联系起来的。


*** t 分布
t 分布并不是仅仅用于小样本（虽然小样本中用的风生水起）中，大样本依旧可以使用。t 分布与正太分布相比多了 *自由度参数* ，在小样本中，能够更好的剔除异常值对于小样本的影响，从而能够准确的抓住数据的集中趋势和离散趋势。

t 分布的性质：厚尾性。当 $n \rightarrow \infty$ 时，t 分布就变成正态分布。

卡方检验在很多课本中被认为是非参数检验的一员，但从分布假设来说，他属于参数检验。卡方分布（x2）是 K 个服从正态分布的随机变量的平方和所服从分布。其参数只有自由度一个，当自由度很大时，X2 近似服从正太分布。

F 分布是两个服从卡方分布的随机变量各自除以他们的自由度的商。

*** 有监督模型
知名的有监督模型包括：K-近邻算法、线性回归、逐步回归模型、逻辑回归、支持向量机、决策树和随机森林、神经网络等。
*** 回归模型理论
根据自变量因子的性质，可以将线性模型分为三类：

1、凡自变量因子都是数量因子， **就称为这个模型是回归分析模型**;

2、如果自变量因子均为属性变量， **则称为模型是方差分析模型**;

3、倘若自变量因子中，既有属性因子，也有数量因子, **就称为协方差分析模型**.

**** 标准化处理
我们都知道在实际应用中，样本不同的特征的单位不同，会在求距离时造成很大的影响。比
如：在两个样本中肿瘤大小分别为 1cm 和 5cm,发现时间分别为 100 天和 200 天，那么在求距离
时，时间差为 100,大小差为 4,那么其结果会被时间所主导，因为肿瘤大小的差距太小了。
但是如果我们把时间用年做单位，0.27 年与 0.55 年的差距又远小于肿瘤的大小的差距，
结果又会被大小所主导。

为了避免上述问题对结果造成影响，就需要对数据做无量纲化处理。常用的数据量纲处理方
式有 2 种：一是标准化处理（Z-score）方法，二是数据归一化。

Z-score 方法的缺点是该方法需要总体的平均平均值与方差，但是这一值在真实的分析与挖
掘中很难得到，大多数情况下是用样本的均值与标准差替代。Z-score 对于数据的分布有一
定的要求，正态分布是最有利于 Z-score 计算的。

minmax 归一化方法：$x = \dfrac{x-min}{max - min}$.

**** MaxAbs 归一化
$x = \dfrac{x}{\abs{MAX}}$

这种方法的缺点是当有新的数据加入时，可能导致 max 和 min 的变化

*** 正态分布分布化
正则化的过程是将每个样本缩放到单位范数。normalization 主要思想是对每个样本计算其
p-范数，然后对该样本中每个元素除以该范数。
公式：$x = \dfrac{x}{\sqrt{\sum^{d}_{j}(x_{ij})^2}}$.

在分类，聚类算法中，需要使用距离来度量相似相似性的时候，标准化表现更好。

不涉及距离度量，协方差计算，数据不符不符合正态分布时，可以使用区间缩放的归一化方
法或其他归一化方法。

*** 一般线性回归
线性回归模型假设有 3 个：

- 自变量非随机；

- 残差期望等于 0, 协方差矩阵对角线等于固定值，非对角线等于 0 ;

- 残差服从 $N(0, \sigma^2)$;

 假定因变量 $Y$ 和自变量 $X$ 满足线性回归模型，其方程为：

 \[
 Y=X\beta+\epsilon
 \]

 式中，因变量 $Y$ 为 $n$ 维向量；自变量 $X$ 为 $n\times p$ 矩阵；误差项 $\epsilon$ 为 $n$ 维向量。需要注意的是在简单回归中，误差项 $\epsilon$ 的元素一般要求是独立同分布零均值的，而通常分布假定为正态的，在最小二乘回归的标准输出中，对系数的 $t$ 检验和方差分析的 F 检验，常常认为 p 值小就意味着“显著”，但需要注意误差是否偏离正态性，如果不考虑正态性或者渐近正态性不成立，那么 t 检验和 F 检验就没有任何意义。

在模型比较过程中，需要注意的是对于不满足正态性假定的模型也可以进行互相比较，但所用方法不是这些基于正态性的检验，可以用 AIC 之类的准则或交叉验证来比较。

#+begin_src ipython :session :exports both :results raw drawer
import numpy as np
from sklearn.linear_model import LinearRegression
X=np.array([[1,1],[1,2],[2,2],[2,3]])
y = np.dot(X, np.array([1, 2])) + 3
reg = LinearRegression().fit(X, y)
reg.score(X, y)
reg.coef_
# => array([1., 2.])
reg.intercept_
# => 3.0000000000000018
reg.predict(np.array([[3, 5]]))
# => array([16.])

#+end_src

#+begin_src python
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.collections import LineCollection
from sklearn.linear_model import LinearRegression
from sklearn.isotonic import IsotonicRegression
from sklearn.utils import check_random_state
n = 100
x = np.arange(n)
rs = check_random_state(0)
y = rs.randint(-50, 50, size=(n, )) + 50.*np.log1p(np.arange(n))

################fit isotonic-regression
ir = IsotonicRegression()
y_ = ir.fit_transform(x, y)
lr = LinearRegression()
lr.fit(x[:, np.newaxis], y)

  segments = [[[i, y[i]], [i, y_[i]]] for i in range(n)]
  lc = LineCollection(segments, zorder=0)
  lc.set_array(np.ones(len(y)))
  lc.set_linewidths(np.full(n, 0.5))

  fig = plt.figure()
  plt.plot(x, y, "r.", markersize=12)
#+end_src

#+BEGIN_SRC Python
import numpy as np
import scipy as sp
from scipy.optimize import leastsq
import matplotlib.pyplot as plt
# 目标函数
def real_func(x):
    return np.sin(2*np.pi*x)

# 多项式
def fit_func(p, x):
    f=np.polyy1d(p)
    return f(x)

# 残差
def residuals_func(p, x, y):
    ret=fit_func(p, x) - y
    return ret

# 构造10个点
x=np.linspace(0, 1, 10)
x_points=np.linspace(0, 1, 1000)
#+END_SRC

*** 相关系数
用来度量两个变量间的线性关系。定义是：

$$
r(X, Y)=\frac{\operatorname{Cov}(X, Y)}{\sqrt{\operatorname{Var}[X] \operatorname{Var}[Y]}}
$$

其中，cov(X, Y) 为 X 与 Y 的协方差， var(X) 是方差。

\begin{equation}
 r=\frac{\sum_{i=1}^{n}\left(X_{i}-\bar{X}\right)\left(Y_{i}-\bar{Y}\right)}{\sqrt{\sum_{i=1}^{n}\left(X_{i}-\bar{X}\right)^{2}} \sqrt{\sum_{i=1}^{n}\left(Y_{i}-\bar{Y}\right)^{2}}}
\end{equation}

协方差如何计算？

\(\sigma(x, y)=\frac{1}{n-1} \sum_{i=1}^{n}\left(x_{i}-\bar{x}\right)\left(y_{i}-\bar{y}\right)\)

方差： \(\sigma_{x}^{2}=\frac{1}{n-1} \sum_{i=1}^{n}\left(x_{i}-\bar{x}\right)^{2}\)

相关系数检验可以用 t 检验来检验 $r$ 是否显著。具体思路如下：

https://upload-images.jianshu.io/upload_images/9689089-1a4ede556d459621.png?imageMogr2/auto-orient/strip|imageView2/2/format/webp

https://upload-images.jianshu.io/upload_images/9689089-87402a9996265b0f.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp

- 不相关与独立之间的关系

两个变量独立则一定能说明两个变量不相关，反之，不相关不一定能推导出两个变量独立，
只能说明两个变量不存在线性关系。

*** 复相关系数
复相关系数是测量一个变量与其他多个变量之间的线性相关程度指标。测定一个变量 $y$
与其他多个变量 $x_{1},x_{2},\dots,x_{k}$ 之间的相关系数。不能直接测算
$x_{1},x_{2},\dots,x_{k}$ 与 $y$ 的相关系数，只能计算 x 的线性组合与 $y$之间的简单
相关系数。

具体计算方法是：

第一步，用 y 对 $x_{1},x_{2},\dots,x_{k}$ 作回归，得：\(\hat{y}=\hat{\beta}_{0}+\hat{\beta}_{1} X_{1}+\cdots+\hat{\beta}_{k} X_{k}\)

第二步，计算简单相关系数，即为 y 与 之间的复相关系数。计算公式是：\(R=\frac{\sum(y-\bar{y})(\hat{y}-\bar{y})}{\sqrt{\sum(y-\bar{y})^{2}(\hat{y}-\bar{y})^{2}}}\)

*** PCA
该算法主要用于降维。

算法流程：

(1) 对原始数据 $X$ 进行归一化处理。

(2) 求出 $X$ 的协方差矩阵 $A = \dfrac{1}{n-1} XX^{T}$

(3) 对 $A$ 进行特征值分解

(4) 取前 $d$ 个特征值对应的特征向量构成转换矩阵 $P$

(5) 通过 $Y=PX$ 对数据进行降维。

*** 典型相关分析
https://blog.csdn.net/Mbx8X9u/article/details/78824216

这个方法的思想和 svm,lda,pca 一样！ CCA(canonical correlation analysis)利用综合变量对之间的相关关系来反映两组指标之间的整体相关性的多元统计分析方法。

它的基本原理是：为了从总体上把握两组指标之间的相关关系，分别在两组变量中提取有代表性的两个综合变量 U1 和 V1（分别为两个变量组中各变量的线性组合），利用这两个综合变量之间的相关关系来反映两组指标之间的整体相关性。

上面提到 CCA 是将高维的两组数据分别降维到 1 维，然后用相关系数分析相关性。但是有一个问题是，降维的标准是如何选择的呢？回想下主成分分析 PCA，降维的原则是投影方差最大；再回想下线性判别分析 LDA，降维的原则是同类的投影方差小，异类间的投影方差大。

对于 CCA, 它选择的投影标准是降维到 1 维后，两组数据的相关系数最大。

计算流程：

输入：各为 $m$ 个样本 $X$ 和 $Y$, $X$ 和 $Y$ 的维度都大于 1。
输出：$X,Y$ 的相关系数 $\rho,X,Y$ 的线性系数向量 $a$ 和 $b$ 。

流程：

1. 计算 X 的方差 SXX, Y 的方差 SYY, X 和 Y 的协方差 SXY.

2. 计算矩阵 \(M=S_{X X}^{-1 / 2} S_{X Y} S_{Y Y}^{-1 / 2}\)

3. 对矩阵 $M$ 进行奇异值分解，得到最大的奇异值 $\rho$,和最大奇异值对应的左右奇异向量。

4. 计算 X 和 Y 的线性系数向量 a 和 b, \(a=S_{X X}^{-1 / 2} u, b=S_{Y Y}^{-1 / 2} v\).

CCA 算法广泛的应用于数据相关度的分析，同时还是偏最小二乘法的基础。但是由于它依赖于数据的线性表示，当我们的数据无法线性表示时，CCA 就无法使用，此时我们可以利用核函数的思想，将数据映射到高维后，再利用 CCA 的思想降维到 1 维，求对应的相关系数和线性关系，这个算法一般称为 KCCA。

#+begin_src ipython :session :exports both :results raw drawer
from sklearn.cross_decomposition import CCA
X = [[0, 0, 1], [1, 0, 0], [2, 2, 2], [3, 5, 4]]
Y = [[0.1, -0.2], [0.9, 1.1], [6.2, 5.9], [11.9, 12.3]]
cca = CCA(n_components=1)
X_c, Y_c =  cca.transform(X, Y)
#+end_src

*** 点估计

假设用 $\hat{\theta}(X)$ 估计 $\theta$, 评价该估计好坏的标准是 MSE 均方误差：
$$
MSE_{\theta}(\hat{\theta}) = E(\hat{\theta}(X)-\theta)^2 = var(\hat{\theta}) +
(E(hat(\theta) - \theta)^2)
$$
很遗憾，上面的 $\hat{\theta}$ 估计的在全局最小的均方误差是不存在的，只能限定一个条件，比如说，在无偏估计中寻找最小的 MSE 估计。其中，$(E(hat(\theta) - \theta)^2)$ 称为估计 $\hat{\theta}$ 的偏差，如果偏差等于 0, 就是所谓的无偏估计。

- 渐近无偏性

设 $\hat{g}_{n}=\hat{g}_{n}\left(X_{1},\ldots,X_{n}\right)$ 是 $g\left(\theta\right)$ 的估计量，若

\[
\text{\ensuremath{\lim_{n\rightarrow\infty}E_{\theta}\left(\hat{g}_{n}\right)=g\left(\theta\right),\forall\theta\in\Theta}}
\]

则称 $\hat{g}_{n}$ 为 $g\left(\theta\right)$ 的渐近无偏估计。

- 相合性

设 $\hat{\theta}_{n}=\hat{\theta}_{n}\left(X_{1},\cdots,X_{n}\right)$ 是
$\theta$ 的估计，如果当 $n\rightarrow\infty$ 时，有

$$
\hat{\theta}_{n}\stackrel{P}{\longrightarrow}\theta
$$

则称 $\hat{\theta}_{n}$ 是 $\theta$ 的弱相合估计，进一步，如果

$$
\hat{\theta}_{n}\rightarrow\theta\text{, a.s.}
$$

则称 $\hat{\theta}_{n}$ 是 $\theta$ 的强相合估计。

不妨有一个例子来说明相合性。设 $X_{1},\cdots,X_{n}$ 是来自
$U\left(0,\theta\right)$ 的一个样本，最大次序统计量 $X_{\{n\}}$ 是 $\theta$ 的常用估计，所谓的次序统计量是指

$$
X_{\{1\}}\leq\cdots\leq X_{\{n\}}
$$

它们的观察值依次记为 $y_{1}\leq\cdots\leq y_{n}$.

假设 $X_{\{n\}}$ 的密度函数 $g\left(y_{k}\right)$, 其中 $1\leq k\leq
n$,$X_{\{n\}}$ 的观察值为 $y_{k}$, 以 $y_{k}$ 为基础把实数轴分为三个区间：

$$
\text{\ensuremath{\left(-\infty\text{，}y_{k}\right)},\ensuremath{\left[y_{k},y_{k}+dy_{k}\right)},\ensuremath{\left[y_{k}+dy_{k},\infty\right)}}
$$

其中第二个区间的长度 $dy_{k}$ 很小，使得样本观察值中只有一个落入该区间，而有两个
或更多个观察值落入该区间的概率为零或为 $o\left(dy_{k}\right)$,这只要使 $dy_{k}$
充分小总可办到，这样一来，要使 $X_{\{k\}}$ 的观察值落入
$\left[y_{k},y_{k}+dy_{k}\right)$ 其内，就要样本的 $n$ 个观察值中有 $k-1$ 个落入
$\left(-\infty\text{，}y_{k}\right)$ 内，有 $n-k$ 个落入
$\left[y_{k}+dy_{k},\infty\right)$ 内，据多项式分布，可算得 $X_{\{k\}}$ 的概率为：

$$
g\left(y_{k}\right)dy_{k}=\frac{n!}{\left(k-1\right)!1!\left(n-k\right)!}\times\left[F\left(y_{k}\right)\right]^{k-1}p\left(y_{k}\right)dy_{k}\left[1-F\left(y_{k}+dy_{k}\right)\right]^{n-k}+o\left(dy_{k}\right)
$$

上面的计算公式真的是很像可测集上的函数计算，$g\left(y_{k}\right)dy_{k}$ 的含义是 $g\left(y_{k}\right)$ 是概率，
$dy_{k}$ 是区间长度。

两边约去 $dy_{k}$ 后，再让 $dy_{k}\rightarrow0$ 即得 $X_{\{k\}}$ 的密度函数为

\[
g\left(y_{k}\right)=\frac{n!}{\left(k-1\right)!\left(n-k\right)!}\times\left[F\left(y_{k}\right)\right]^{k-1}\left[1-F\left(y_{k}\right)\right]^{n-k}p\left(y_{k}\right)
\]
那么，$X_{\{1\}}$ 与 $X_{\{n\}}$ 的密度函数分布为

\[
g\left(y_{1}\right)=n\left[1-F\left(y_{1}\right)\right]^{n-1}p\left(y_{1}\right)
\]
\[
g\left(y_{n}\right)=n\left[F\left(y_{n}\right)\right]^{n-1}p\left(y_{n}\right)
\]

所以，设 $X_{1},\cdots,X_{n}$ 是来自 $U\left(0,\theta\right)$ 的一个样本，最大次序统计量 $X_{\{n\}}$ 是 $\theta$ 的常用估计，所谓的次序统计量是指

\[
X_{\{1\}}\leq\cdots\leq X_{\{n\}}
\]

它们的观察值依次记为为 $y_{1}\leq\cdots\leq y_{n},$ 容易知道 $X_{\{n\}}$ 的密度函数为

\[
p\left(t;\theta\right)=nt^{n-1}\theta^{-n},0<t<\theta
\]

容易求出$E\left(X_{\text{\{n\}}}\right)=n\theta/(n+1)$,因此 $X_{\{n\}}$ 不是 $\text{\ensuremath{\theta}}$ 的无偏估计，但是它是 $\text{\ensuremath{\theta}}$ 的渐近无偏估计，另外，由于对任意的 $\varepsilon\text{>0,}$

\[
P_{\theta}\left(\left|X_{\{n\}}-\theta\right|\geqq\varepsilon\right)=P_{\theta}\left(X_{\{n\}}\leqq\theta-\varepsilon\right)=\intop_{0}^{\theta-\epsilon}\frac{nt^{n-1}}{\theta^{n}}dt=\left(\frac{\theta-\epsilon}{\theta}\right)^{n}\rightarrow0\left(n\rightarrow\infty\right)
\]

因此, $X_{\{n\}}$ 是 $\text{\ensuremath{\theta}}$ 的相合估计。

*** MLE
极大似然估计 MLE 有一个很好的性质：如果 $\theta$ 是 $\theta$ 的 MLE, $g(\dot)$ 是可测函数（什么是可测函数？），则 $g(\hat{\theta})$ 也是 $g(\theta)$ 的 MLE.该性质称为 MLE 的不变性。

*** stepwise regression

包括 2 个步骤：一是从回归模型中剔出经检验不显著的变量，二是引入新变量到回归模型中。

1.先对所有 X,建立一元回归模型，计算回归系数的 F 检验统计量的值，取其中最大的值 F,
如果给定显著水平 $\alpha$, 记相应的临界值为 $F2$, $F2 > F$, 将 $X_{i}$ 引入模型。

2.建立因变量 $Y$ 与自变量 $X_{i}, X_{1}$ 的二元回归模型，计算 F 统计量，选最大的 F
统计量对应的自变量入模。

3.重复步骤 2 .

*** lasso
**** coordinate descent
这个方法的优势在于简单。

#+begin_quote
Minimize over one parameter at a time, keeping all others fixed.
#+end_quote

每次只求解一个参数值，保证其他参数值不变。如果是求解单个特征，那么其实很简单，就是一个软阈值函数。

\begin{equation}
\operatorname{sign}(\hat{\beta})(|\hat{\beta}|-\gamma)_{+}
\end{equation}

那么，对于多元回归而言，相当于每次固定一个 X,求解它的 beta,这样相当于每次只求解一
个特征，会变得很容易。

\begin{equation}
\tilde{\beta}_{j}(\lambda) \leftarrow S\left(\sum_{i=1}^{n} x_{i j}\left(y_{i}-\tilde{y}_{i}^{(j)}\right), \lambda\right)
\end{equation}

where \(S(t, \lambda)=\operatorname{sign}(t)(|t|-\lambda)_{+}, \tilde{y}_{i}^{(j)}=\sum_{k \neq j} x_{i k} \tilde{\beta}_{k}(\lambda)\)

     #+begin_src R :results output graphics :file fig_1.png :exports both
       # LASSO WITH ALPHA = 1
       cv1 <- cv.glmnet(mdlX, mdlY, family = "binomial", nfold = 10, type.measure = "deviance", paralle = TRUE, alpha = 1)
       md1 <- glmnet(mdlX, mdlY, family = "binomial", lambda = cv1$lambda.1se, alpha = 1)
       coef(md1)
     #+end_src
*** adaptive lasso
\(Q(\boldsymbol{\beta} \mid \mathbf{X}, \mathbf{y}, \mathbf{w})=\frac{1}{2 n}\|\mathbf{y}-\mathbf{X} \boldsymbol{\beta}\|^{2}+\lambda \sum_{j} w_{j}\left|\beta_{j}\right|\)

where \(w_{j}=\left|\widetilde{\beta}_{j}\right|^{-1}\)

*** elasticnet

    #+begin_src R :results output graphics :file fig_1.png :exports both
      # ELASTIC NET WITH 0 < ALPHA < 1
      a <- seq(0.1, 0.9, 0.05)
      search <- foreach(i = a, .combine = rbind) %dopar% {
          cv <- cv.glmnet(mdlX, mdlY, family = "binomial", nfold = 10, type.measure = "deviance", paralle = TRUE, alpha = i)
          data.frame(cvm = cv$cvm[cv$lambda == cv$lambda.1se], lambda.1se = cv$lambda.1se, alpha = i)
      }
      cv3 <- search[search$cvm == min(search$cvm), ]
      md3 <- glmnet(mdlX, mdlY, family = "binomial", lambda = cv3$lambda.1se, alpha = cv3$alpha)
      coef(md3)
    #+end_src

*** SCAD
 \begin{equation}
 Q(\boldsymbol{\beta} \mid \mathbf{X}, \mathbf{y})=\frac{1}{2 n}\|\mathbf{y}-\mathbf{X} \boldsymbol{\beta}\|^{2}+\sum_{j=1}^{p} P\left(\beta_{j} \mid \lambda, \gamma\right)
\end{equation}

where \(P(\beta \mid \lambda, \gamma)\) is a folded concave penalty.

SCAD penalty

\begin{equation}
 P(x \mid \lambda, \gamma)=\left\{\begin{array}{ll}\lambda|x| & \text { if }|x| \leq \lambda \\ \frac{2 \gamma \lambda|x|-x^{2}-\lambda^{2}}{2(\gamma-1)} & \text { if } \lambda<|x|<\gamma \lambda \\ \frac{\lambda^{2}(\gamma+1)}{2} & \text { if }|x| \geq \gamma \lambda\end{array}\right.
\end{equation}

for $\gamma > 2$

*** MCP
 \begin{equation}
 Q(\boldsymbol{\beta} \mid \mathbf{X}, \mathbf{y})=\frac{1}{2 n}\|\mathbf{y}-\mathbf{X} \boldsymbol{\beta}\|^{2}+\sum_{j=1}^{p} P\left(\beta_{j} \mid \lambda, \gamma\right)
\end{equation}

where \(P(\beta \mid \lambda, \gamma)\) is a folded concave penalty.

\begin{equation}
 \begin{array}{l}\quad P_{\gamma}(x ; \lambda)=\left\{\begin{array}{ll}\lambda|x|-\frac{x^{2}}{2 \gamma}, & \text { if }|x| \leq \gamma \lambda \\ \frac{1}{2} \gamma \lambda^{2}, & \text { if }|x|>\gamma \lambda\end{array}\right. \\ \text { for } \gamma>1\end{array}
\end{equation}

The primary way in which adaptive lasso, SCAD, and MCP differ from the lasso is
that they allow the estimated coefficients to reach large values more quickly than the lasso.

相比较 lasso, scad, mcp, adaptive lasso 可以很快速地让参数估计达到一个较大值，也
就是说后面三个方法对于非零系数压缩的幅度比 lasso 小多了。

The tuning parameter $\gamma$ for the SCAD and MCP estimates controls how fast
the penalization rategoes to zero. $\gamma$ 的作用在于能够控制参数系数压缩到 0 的
速度。反过来，这会影响估计的偏差以及估计的稳定性，因为随着惩罚变得越来越凹，存在多个局部最小值的机会更大。

*** group lasso
In many regression problems, however, predictors are notdistinct but arise from
common underlying factors. 现实生活中，许多变量均是成组出现的。

- We denote \(\mathbf{X}\) as being composed of \(J\) groups
\(\mathbf{X}_{1}, \mathbf{X}_{2}, \ldots, \mathbf{X}_{J},\) with \(K_{j}\) denoting the size of group \(j ;\) i.e.,
\(\sum_{j} K_{j}=p\)

- As usual, we are interested in estimating a vector of
coefficients \(\boldsymbol{\beta}\) using a loss function \(L\) which quantifies the
discrepancy between the observations \(\mathbf{y}\) and the linear
predictors \(\boldsymbol{\eta}=\mathbf{X} \boldsymbol{\beta}=\sum_{j} \mathbf{X}_{j} \boldsymbol{\beta}_{j},\) where \(\boldsymbol{\beta}_{j}\) represents the
coefficients belonging to the \(j\) th group

- Covariates that do not belong to a group may be thought ofas a group of one

形式是：

\begin{equation}
 \mathbf{Q}(\boldsymbol{\beta} \mid \mathbf{X}, \mathbf{y})=\mathbf{L}(\boldsymbol{\beta} \mid \mathbf{X}, \mathbf{y})+\sum_{j} \lambda_{j}\left\|\boldsymbol{\beta}_{j}\right\|
\end{equation}

需要注意的是 $\left\|\boldsymbol{\beta}_{j}\right\|$ 反应的是一组 beta.

To ensure that the same degree of penalization is applied to
large and small groups, \(\lambda_{j}=\lambda \sqrt{K_{j}}\)

为了确保变量数量多的组和数量较少组的惩罚力度一样，一般将 \(\lambda_{j}=\lambda \sqrt{K_{j}}\)。

估算参数的算法如下，名称是 blockwise coordinate descent, 成组坐标下降法：

repeat

for \(j=1,2, \ldots, J\)

\(\quad \mathbf{z}_{j}=\mathbf{X}_{j}^{T} \mathbf{r}+\boldsymbol{\beta}_{j}\)

\(\boldsymbol{\beta}_{j}^{\prime} \leftarrow S\left(\left\|\mathbf{z}_{j}\right\|, \lambda_{j}\right) \mathbf{z}_{j} /\left\|\mathbf{z}_{j}\right\|\)

\(\mathbf{r}^{\prime} \leftarrow \mathbf{r}-\mathbf{X}_{j}\left(\boldsymbol{\beta}_{j}^{\prime}-\boldsymbol{\beta}_{j}\right)\)
until convergence

For MCP/SCAD, we would replace the soft thresholding step withthe appropriate thresholding operatorPatrick BrehenyHigh-Dimensional Data Analysis (BIOS 7600)15/26

*** group mcp

形式和 group lasso 类似，不同的是惩罚项函数，换成 \(P(\boldsymbol{\beta})=\sum_{j} \operatorname{MCP}\left(\left\|\boldsymbol{\beta}_{j}\right\| ; \lambda_{j}, \gamma\right)\)。

*** group scad
*** Ridge
    #+begin_src R :results output graphics :file fig_1.png :exports both
      cv2 <- cv.glmnet(mdlX, mdlY, family = "binomial", nfold = 10, type.measure = "deviance", paralle = TRUE, alpha = 0)
      md2 <- glmnet(mdlX, mdlY, family = "binomial", lambda = cv2$lambda.1se, alpha = 0)
      coef(md2)
    #+end_src

*** logistic 回归模型

#+begin_quote
If I were to be treated by a cure created by stepwise regression, I would prefer voodoo.
   -- Dieter Menne (in a thread about regressions with many variables)
      R-help (October 2009)
#+end_quote

这种方法有很多优点，例如它是直接对分类可能性进行建模，无需事先假设数据分布，这样就避免了假设分布不准确所带来的问题，它不仅预测出类别，而是可得到近似概率预测，这对许多需利用概率预测辅助决策的任务很有用；此外，对率函数是任意阶可导的凸函数，有很好的数学性质。


当样本量大时，推荐将数据分成训练集和测试集，分别用于变量选择\模型调优和验证最终
模型（以及变量集合）。对于小样本训练集，选择合适的重抽样方法非常关键。
**** 模型形式
Sppose the response variable $Y_{i}$ for $i=1,\cdots,n_{i}$ is binomially distributed $B(n_{i},p_{i})$ so that:
\begin{equation}
P\left(Y_{i}=y_{i}\right)=\left(\begin{array}{l}{n_{i}} \\ {y_{i}}\end{array}\right) p_{i}^{y_{i}}\left(1-p_{i}\right)^{n_{i}-y_{i}}
\end{equation}

we further assume that the $Y_{i}$ are independent.The individual trials that compose the response $Y_{i}$ are all subject to the same $q$ predictors $(x_{i1},\cdot,x_{iq})$.The group of trials is known as a /covariate class/. we need a model that describes the relationship of $x_{1},\cdot,x_{q}$ to $p$.Following the linear model approach, we construct a /linear predictor/:

\begin{equation}
\eta_{i}=\beta_{0}+\beta_{1} x_{i 1}+\ldots+\beta_{q} x_{i q}
\end{equation}

we have already seen above that setting $\eta_{i}=p_{i}$ is not appropriate because we require $0 \leq p_{i} \leq 1$.Instead we shall use a link function $g$ such that $\eta_{i}=g(p_{i})$.For this application,we shall need $g$ to be monotone and be such that $0\leq g^{-1}(\eta)\leq 1$ for any $\eta$.There are three common choices:

1.logit:$\eta=log(p/(1-p))$.
2.probit:$\eta=\Phi^{-1}(p)$ where $\Phi^{-1}$ is the inverse normal cumulative distribution function.
3.Complementary log-log:$\eta=\log(-log(1-p))$

再作补充：

\begin{equation}
\begin{aligned} p(y=1 | \mathbf{x}) &=\sigma\left(\mathbf{w}^{\mathrm{T}} \mathbf{x}+b\right)=\frac{\exp \left(\mathbf{w}^{\mathrm{T}} \mathbf{x}+b\right)}{1+\exp \left(\mathbf{w}^{\mathrm{T}} \mathbf{x}+b\right)} \\ p(y=-1 | \mathbf{x}) &=1-\sigma\left(\mathbf{w}^{\mathrm{T}} \mathbf{x}+b\right)=\frac{1}{1+\exp \left(\mathbf{w}^{\mathrm{T}} \mathbf{x}+b\right)} \end{aligned}
\end{equation}

上式中，链接函数可以换成 probit 或者 log-log 等.

\[
\operatorname{logit}\left(p_{i}\right)=\log \left(\frac{p_{i}}{1-p_{i}}\right)=\beta_{0}+\beta_{1} x_{1 i}+\cdots+\beta_{k} x_{k i}
\]

$$
p_{i}=\frac{\exp \left(\beta_{0}+\beta_{1} x_{1 i}+\cdots+\beta_{k} x_{k i}\right)}{1+\exp \left(\beta_{0}+\beta_{1} x_{1 i}+\cdots+\beta_{k} x_{k i}\right)}
$$

观测 $y_{i}$ 服从于一个二项分布，均值是 $n_{i}p_{i}$,能够表示为 $y_{i}=n_{i}p_{i}+\epsilon_{i}$,残差部分 $\epsilon_{i}=y_{i}-n_{i}p_{i}$ 是零均值，但是不再服从的是二项分布，实际上， $\epsilon$ **服从的是位移二项分布**.

需要补充的是：$E\left(\varepsilon_{i} | X_{i}\right)=0$,即给定 X 的前提下，$\varepsilon_{i}$ 的期望为 0.

\begin{equation}
 \varepsilon_{j}=\left\{\begin{array}{ll}{1-X_{j}^{\prime} \beta} & {\left(Y_{i}=1\right)} \\ {-X_{i}^{\prime} \beta} & {\left(Y_{j}=0\right)}\end{array}\right.
\end{equation}

上式为 logistic 回归模型的残差，可以看出是二元变量，而不是我们通常假定的正态分布。

【问题？】
什么是位移二项分布？

似然函数

$$
L(\boldsymbol{\beta})=\prod_{i=1}^{n}\left(\begin{array}{l}{n_{i}} \\ {y_{i}}\end{array}\right) p_{i}^{y_{i}}\left(1-p_{i}\right)^{n_{i}-y_{i}}
$$

\begin{aligned} \log L(\boldsymbol{\beta}) &=\sum_{i=1}^{n}\left\{\log \left(\begin{array}{l}{n_{i}} \\ {y_{i}}\end{array}\right)+y_{i} \log p_{i}+\left(n_{i}-y_{i}\right) \log \left(1-p_{i}\right)\right\} \\ &=\sum_{i=1}^{n}\left\{\log \left(\begin{array}{c}{n_{i}} \\ {y_{i}}\end{array}\right)+y_{i} \log \left(\frac{p_{i}}{1-p_{i}}\right)+n_{i} \log \left(1-p_{i}\right)\right\} \\ &=\sum_{i=1}^{n}\left\{\log \left(\begin{array}{l}{n_{i}} \\ {y_{i}}\end{array}\right)+y_{i} \eta_{i}-n_{i} \log \left(1+e^{\eta_{i}}\right)\right\} \end{aligned}

$$
\frac{\partial \log L(\boldsymbol{\beta})}{\partial \beta_{j}}=\sum_{i=1}^{n} y_{i} x_{j i}-\sum_{i=1}^{n} n_{i} x_{j i} e^{\eta_{i}}\left(1+e^{\eta_{i}}\right)^{-1}, \quad j=0,1, \ldots, k
$$

以下解释更为清晰！！

另外一种解释是：
\begin{equation}
\begin{aligned} \ln L(\mathbf{w}) &=\sum_{i=1}^{N} \ln p\left(y_{i} | \mathbf{x}_{i}\right) \\ &=\sum_{i=1}^{N} y_{i} \ln \sigma\left(\mathbf{w}^{T} \mathbf{x}_{i}\right)+\left(1-y_{i}\right) \ln \left[1-\sigma\left(\mathbf{w}^{T} \mathbf{x}_{i}\right)\right] \\ &=\sum_{i=1}^{N} y_{i} \ln \frac{\sigma\left(\mathbf{w}^{T} \mathbf{x}_{i}\right)}{1-\sigma\left(\mathbf{w}^{T} \mathbf{x}_{i}\right)}+\ln \left[1-\sigma\left(\mathbf{w}^{T} \mathbf{x}_{i}\right)\right] \\ &=\sum_{i=1}^{N}\left(y_{i} \mathbf{w}^{T} \mathbf{x}_{i}-\ln \left[1+\exp \left(\mathbf{w}^{T} \mathbf{x}_{i}\right)\right]\right) \end{aligned}
\end{equation}

所以负对数似然 (log-likelihood),求导可知：

\begin{equation}
-\ln L(w)=\sum_{i=1}^{N} \ln \left(1+\exp \left(w^{T} x_{i}\right)\right)-y_{i} w^{T} x_{i}
\end{equation}


注意到这里 $p\left(y_{i} | \mathbf{x}_{i}\right)$ 是单个观测服从的是伯努利分布
$p^{y}*(1-p)^{1-y}$,这里的 \(p(y=1 | \mathbf{x})=\sigma\left(\mathbf{w}^{\mathbf{T}} \mathbf{x}+b\right)\)。

可知，上式是没有办法求解 $\beta$ 的精确解，只能求得数值解。一个广泛的求解方法就是 Fisher ’s 得分法，此法相当于是一个重复加权最小二乘方法, $z_{i}=\eta_{i}+(y_{i}-n_{i}p_{i})/\{n_{i}p_{i}(1-p_{i})\}$,weight 等于 $n_{i}p_{i}(1-p_{i})$.

一些有用的结论：

- 随着样本量 $n$ 的增加，二项分布近似于正态分布.随机变量 $Z=\frac{Y-n p}{\sqrt{\{} n p(1-p)\}}$ 接近正态分布。McCullagh 等人证明 *当 $np(1-p)\ge2$,随机变量 Y 即可满足正态分布假设* ，特别是当 $p$ 接近于 0.5 的时候，所以当 n 等于 10 的时候，二项分布近似于正态分布。

在样本量足够大时，二项分布近似于正态分布。其实也可以利用线性模型拟合逾期率：

$y_{i}=0$ 为失败，$y_{i}=1$ 为成功。$E(Y_{i})=n_{i}p_{i}$,$var(Y_{i})=n_{i}p_{i}(1-p_{i})$

$$
\sum_{i=1}^{n}\left(\frac{y_{i}}{n_{i}}-p_{i}\right)^{2}=\sum_{i=1}^{n}\left(\tilde{p}_{i}-\beta_{0}-\beta_{1} x_{1 i}-\cdots-\beta_{k} x_{k i}\right)^{2}
$$

但是这种方法有很多的缺点：比如，异方差问题，$\operatorname{var}\left(\tilde{p}_{i}\right)=p_{i}(1-p_{i})/n_{i}$,当 $p_{i}$ 在 0.25-0.75 时, \(0.19 < p_{i}(1-p_{i}) < 0.25\) 也就是方差不会相差很大，但是 p 值很大或者很小的时候，那么方差变化就会很大！一种解决的方法就是加权回归模型 $\sum_{i=1}^{n} w_{i}\left(\tilde{p}_{i}-p_{i}\right)^{2}$.第二个问题就是正态分布，当 n 很大的时候，这个问题不存在。第三个问题就是，估计值可能是负数！而 $\hat{p}$ 不可能是负数！

所以，需要对成功概率 $p$ 作 logit 变换 $log(p/(1-p))$,可以写作 $logit(p)$.logit 变换后，值域就变成了 $(-\inf,\inf)$.

simulation of glm

#+BEGIN_SRC R :exports both :results graphics :file ./fig_1.png
  ##两个特征高度相关
  library(MASS)
  n=1000
  #inv.logit 其实就是 P
  inv.logit <- function(p){
      return(exp(p)/(1+exp(p)))
  }
  Sigma <- matrix(c(1,0.9,0.9,1),2,2)
  X=mvrnorm(n = 1000, rep(0, 2), Sigma)
  beta1=c(0.5,1.5)
  Y=rbinom(n,1,inv.logit(1+X%*%beta1+rnorm(1000,0,1)))
  data=data.frame(Y,X)
  glm(Y~1+.,data = data,family = "binomial")
  #####特征重复2份
  library(MASS)
  x1=rnorm(1000,mean = 0,sd=1)
  X=matrix(rep(x1,2),nrow = 1000)
  beta1=c(0.5,1.5)
  Y=rbinom(n,1,inv.logit(1+X%*%beta1+rnorm(1000,0,1)))
  data=data.frame(Y,X)
  glm(Y~1+.,data = data,family = "binomial")
#+END_SRC

**** 模型推断
logistic 回归模型估计算法为 iteratively reweighted least squares(IRLS). 这个算法
的思路也很简单就是：
\(\mathbf{w}^{n e w}=\mathbf{w}^{o l d}-\mathbf{H}^{-1} \mathbf{g}\)
这里的 $H$ 和 $g$ 分别是二阶导和一阶导。

\begin{equation}
\begin{aligned} \mathbf{H} &=\lambda \mathbf{I}+\mathbf{X} \mathbf{A} \mathbf{X}^{\mathrm{T}} \\ \mathbf{g} &=\lambda \mathbf{w}-\sum_{i=1}^{N} y_{i} \mathbf{x}_{i}\left[1-\sigma\left(y_{i} \mathbf{w}^{T} \mathbf{x}_{i}\right)\right] \\ &=\lambda \mathbf{w}-\mathbf{X} \mathbf{A} \mathbf{t} \end{aligned}
\end{equation}

作补充，

\begin{equation}
\begin{aligned} \mathbf{g} &=\frac{d}{d \mathbf{w}} f(\mathbf{w})=\sum_{i}\left(\mu_{i}-y_{i}\right) \mathbf{x}_{i}=\mathbf{X}^{T}(\boldsymbol{\mu}-\mathbf{y}) \\ \mathbf{H} &=\frac{d}{d \mathbf{w}} \mathbf{g}(\mathbf{w})^{T}=\sum_{i}\left(\nabla_{\mathbf{w}} \mu_{i}\right) \mathbf{x}_{i}^{T}=\sum_{i} \mu_{i}\left(1-\mu_{i}\right) \mathbf{x}_{i} \mathbf{x}_{i}^{T} \\ &=\mathbf{X}^{T} \mathbf{S} \mathbf{X} \end{aligned}
\end{equation}

这里的 $\mu_{i}=\frac{1}{1+\exp \left(-\mathbf{w_{i}}^{T} \mathbf{x_{i}}\right)}$.

总之就有，
\begin{equation}
\begin{aligned} \mathbf{w}^{\text {new }} &=\mathbf{w}^{\text {old }}-\mathbf{H}^{-1} \mathbf{g} \\ &=\mathbf{w}^{\text {old }}-\left(\mathbf{X} \mathbf{A} \mathbf{X}^{\mathbf{T}}+\lambda \mathbf{I}\right)^{-1} \mathbf{g} \\ &=\left(\mathbf{X} \mathbf{A} \mathbf{X}^{\mathbf{T}}+\lambda \mathbf{I}\right)^{-1}\left(\mathbf{X} \mathbf{A} \mathbf{X}^{\mathbf{T}} \mathbf{w}^{\text {old }}+\lambda \mathbf{w}^{\text {old }}-\mathbf{g}\right) \\ &=\left(\mathbf{X} \mathbf{A} \mathbf{X}^{\mathbf{T}}+\lambda \mathbf{I}\right)^{-1}\left(\mathbf{X} \mathbf{A} \mathbf{X}^{\mathbf{T}} \mathbf{w}^{\text {old }}+\mathbf{X} \mathbf{A} \mathbf{t}\right) \\ &=\left(\mathbf{X} \mathbf{A} \mathbf{X}^{\mathbf{T}}+\lambda \mathbf{I}\right)^{-1} \mathbf{X} \mathbf{A}\left(\mathbf{X}^{T} \mathbf{w}^{\text {old }}+\mathbf{t}\right) \\ &=\left(\mathbf{X} \mathbf{A} \mathbf{X}^{\mathbf{T}}+\lambda \mathbf{I}\right)^{-1} \mathbf{X} \mathbf{A} \mathbf{z} \end{aligned}
\end{equation}

其中，\(\mathbf{z}=\mathbf{X}^{T} \mathbf{w}^{o l d}+\mathbf{t}\), 即
\(z_{i}=\mathbf{x}_{i}^{T} \mathbf{w}^{o l d}+t_{i}=\mathbf{x}_{i}^{T}
\mathbf{w}^{o l d}+\frac{y_{i}\left[1-\sigma\left(y_{i} \mathbf{w}^{T}
\mathbf{x}_{i}\right)\right]}{A_{i i}}\), 向量 $\mathbf{t}$ 的第 $i$ 个元素为 \(t_{i}=\frac{y_{i}\left[1-\sigma\left(y_{i} \mathbf{w}^{T} \mathbf{x}_{i}\right)\right]}{A_{i i}}\).

**** logistic 回归求导
这个文档对目的是了解 logistic 回归的求解过程。首先是写清楚 logistic 回归的似然。

$$
l\left(b,y\right)=\sum_{i=1}^{n}y_{i}\log h\left(x_{i}^{T}b\right)+\left(1-y_{i}\right)\log\left(1-h\left(x_{i}^{T}b\right)\right)$$
$$h\left(x_{i}^{T}b\right)=\frac{1}{1+e^{-x}}$$

所以

$$h^{'}\left(x_{i}^{T}b\right)=h\left(x_{i}^{T}b\right)\left(1-h\left(x_{i}^{T}b\right)\right)$$

对其求导可知，

$\frac{\partial l}{\partial b_{j}}=\sum_{i=1}^{n}\frac{y_{i}}{h\left(x_{i}^{T}b\right)}h^{'}\left(x_{i}^{T}b\right)x_{ij}-\frac{1-y_{i}}{1-h\left(x_{i}^{T}b\right)}h^{'}\left(x_{i}^{T}b\right)x_{ij}$

$=\sum_{i=1}^{n}x_{ij}h^{'}\left(x_{i}^{T}b\right)\left(\frac{y_{i}}{h\left(x_{i}^{T}b\right)}-\frac{1-y_{i}}{1-h\left(x_{i}^{T}b\right)}\right)$

$=\sum_{i=1}^{n}x_{ij}\frac{h^{'}\left(x_{i}^{T}b\right)}{h\left(x_{i}^{T}b\right)\left(1-h\left(x_{i}^{T}b\right)\right)}\left(y_{i}-h\left(x_{i}^{T}b\right)\right)$

对于 logistic 回归而言，

$$h^{'}\left(x_{i}^{T}b\right)=h\left(x_{i}^{T}b\right)\left(1-h\left(x_{i}^{T}b\right)\right)$$

所以，

$\frac{\partial l}{\partial b_{j}}=\sum_{i=1}^{n}x_{ij}\left(y_{i}-h\left(x_{i}^{T}b\right)\right)=X^{T}\left(y-\hat{y}\right)$

进一步，$\frac{\partial^{2}l}{\partial b_{k}\partial b_{j}}=-\sum_{i}x_{ij}x_{ik}\frac{\partial}{\partial b_{k}}h\left(x_{i}^{T}b\right)=-\sum_{i}x_{ij}x_{ik}h\left(x_{i}^{T}b\right)\left(1-h\left(x_{i}^{T}b\right)\right)$,也就是说 $H=-X^{T}WX$.

现设$z=W^{-1}\left(y-\hat{y}\right),\frac{\partial l}{\partial b_{j}}=X^{T}Wz$,有了一阶导和二阶导信息，那么就有

$b^{\left(m+1\right)}=b^{\left(m\right)}+\left(X^{T}W_{(m)}X\right)^{-1}X^{T}(y-\hat{y})$

*** LDA(线性判别分析)
是一种经典的线性学习方法。LDA 的思想是：给定训练样例集，设法将样例投影到一条直线上，使得同类样例的投影点尽可能接近，异类样例的投影点尽可能远离。

在对新样本进行分类时，将其投影到同样的这条直线上，再根据投影点的位置来确定新样本的类别。

*** 变量编码
**** woe 编码
证据权重的优点是特征变量的数量不会增加（虚拟变量要生成其他变量），所以不同变量之间相关的可能性会变得更小，且在统计估计时稳健性也会更好。
但缺点是只可以选择性地保留某个特征的全部属性或者一个也不保留。使用虚拟变量时，由于每个特征会生成多个变量，而很正常的是，某个评分卡只用到其中的一些属性变量，但这些属性却被其他评分卡剔除。

#+BEGIN_SRC R :exports both :results graphics :file ./fig_1.png
mifi_model_feature_woe_encoding_all(df, feat_cuts, category_feature_names = NULL,
  label_identify, encoding_path, missing_val = -1, is_debug = F)
#+END_SRC

**** one-hot 编码

#+begin_src python :results output
class OneHotEncoder:
    def __init__(self,optionKeys):
        length=len(optionKeys)
        self.__dict__={optionKeys[j]:[0 if i!=j else 1 for i in range(length)] for j in range(length)}

感知机是根据输入实例的特征向量 $x$ 对其进行二分类的线性分类模型：

\[
f(x)=\operatorname{sign}(w \cdot x+b)
\]

感知机模型对应于输入空间（特征空间）中的分离超平面 $w * x +b = 0$.

\(\operatorname{sign}(x)=\left\{\begin{array}{ll}+1, & x \geqslant 0 \\ -1, & x<0\end{array}\right.\)
感知机学习的策略是最小化损失函数：

#+begin_src python
import pandas as pd
import numpy as np
from sklearn.datasets import load_iris
import matplotlib.pyplot as plt
iris = load_iris()
#+end_src

线性可分数据集的定义：


** 集成学习
*** BOOSTING
*freidman 等人证明如果是二分类问题，那么 boosting 可以近似看作是 additive logistic model。如果是多分类问题，那么就是分布函数是多项分布。*

**** adaboost

结论 1:The Discrete AdaBoost algorithm (population version) builds an additive logistic regression model via Newton-like updates for minimizing \(E\left(e^{-y F(x)}\right)\).

结论 2:The Real AdaBoost algorithm fits an additive logistic regression model by stagewise and approximate optimization of \(J(F)=E\left[e^{-y F(x)}\right] .\)


The AdaBoost procedure trains the classiﬁers $f_{m}(x)$ on weighted versions of
the training sample, giving higher weight to cases that are cur- rently
misclassiﬁed. 每次更新样本权重，分类错误的样本下次给与的权重越大。
This is done for a sequence of weighted samples, and then the ﬁnal classiﬁer is deﬁned to be a linear combination of the classiﬁers from each stage.

Interestingly, in many examples the test error seems to consistently decrease and then level off as more classiﬁers are added, rather than ultimately increase. For some reason, it seems that AdaBoost is resistant to overﬁtting.

有趣的是，在许多示例中，随着添加更多分类器，测试误差似乎一直在下降，然后趋于平稳，而不是最终增加。出于某种原因，AdaBoost 似乎可以抵抗过拟合。

- additive models

\(E(y \mid x)=F(x)\),

\begin{equation}
F(x)=\sum_{j=1}^{p} f_{j}\left(x_{j}\right)
\end{equation}

![real adaboost](https://cdn.mathpix.com/snip/images/sysfs_rZNFyt5ICgafNllVKtuDhKfC7UG8csr1OpOTQ.original.fullsize.png)

1.给定样本初始权重。
2.利用基学习器判定样本分类结果，如果分错加大权重，分对就降低样本权重
3.根据新的权重，再利用基学习器学习分类结果，再判断分错就加大样本权重，分对就降低
样本权重，
4.然后继续迭代，直至误差损失不在降低。

stacking 是一种组合分类器的方法，以两层为例，第一层由多个基学习器组成，其输入为原始训练集，第二层的模型则是以第一层基学习器的输入作为训练集进行再训练（一般用 LR 进行回归组合），从而得到完整的 stacking 模型。

**** XGBoost
最优切分点算法有哪些？

参数估计方法：XGBoost 在函数空间中用牛顿法进行优化。XGBoost 的目标函数：

\begin{equation}
\mathcal{L}(\phi)=\sum_{i} l\left(\hat{y}_{i}, y_{i}\right)+\sum_{k} \Omega\left(f_{k}\right)
\end{equation}

相比较 GBDT,XGBoost 的目标函数多了一个正则项，使得学习出来的模型更加不容易过拟合。

树的深度、内部节点个数、叶子节点个数（T）、叶节点分数（w） 可以衡量树的复杂度。XGBoost 采用的规则是

\begin{equation}
\Omega(f)=\gamma T+\frac{1}{2} \lambda\|w\|^{2}
\end{equation}

从上面的式子，对叶子节点个数进行惩罚，相当于在训练过程中做个剪枝。如何确定树结构？主要还是计算树分裂前后的增益？

ID3 算法采用信息增益；C4.5 算法采用信息增益比; CART 采用 Gini 系数；XGBoost 还是对一个叶子节点进行分裂，分裂前后的增益，当对一个叶节点分割时，计算所有候选对应的 gain,选取 gain 最大的进行分割。
xgboost 的 python code.

#+begin_src python
import pandas as pd
import xgboost as xgb
from sklearn.metrics import mean_squared_error
import pandas as pd
from sklearn.datasets import load_boston
import numpy as np
boston = load_boston()
print(boston.keys())
print(boston.feature_names)
data = pd.DataFrame(boston.data)
data.columns = boston.feature_names
data['PRICE'] = boston.target
data.info()
data.describe()
X, y = data.iloc[:,:-1], data.iloc[:,-1]
data_dmatrix = xgb.DMatrix(data=X, label=y)
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)

xg_reg = xgb.XGBRegressor(objective ='reg:linear', colsample_bytree = 0.3, learning_rate = 0.1,
                max_depth = 5, alpha = 10, n_estimators = 10)

xg_reg.fit(X_train,y_train)
preds = xg_reg.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, preds))
print("RMSE: %f" % (rmse))

params = {"objective":"reg:linear",'colsample_bytree': 0.3,'learning_rate': 0.1,
                'max_depth': 5, 'alpha': 10}

cv_results = xgb.cv(dtrain=data_dmatrix, params=params, nfold=3,
                    num_boost_round=50,early_stopping_rounds=10,metrics="rmse", as_pandas=True, seed=123)
cv_results.head()
print((cv_results['test-rmse-mean']).tail(1))

xg_reg = xgb.train(params=params,
                   dtrain = data_dmatrix,
                   num_boost_round=10)

import matplotlib.pyplot as plt
xgb.plot_tree(xg_reg, num_trees=0)
plt.rcParams['figure.figsize'] = [50, 10]
plt.show()
xgb.plot_importance(xg_reg)
plt.rcParams['figure.figsize'] = [5, 5]
plt.show()
#+end_src

有必要对 xgboost 超参数进行整理。

- （学习率）learning_rate: step size shrinkage used to prevent overfitting. Range is [0,1]

- （树的最大深度）max_depth: determines how deeply each tree is allowed to grow during any boosting round.

- （每棵树的抽样比率）subsample: percentage of samples used per tree. Low value can lead to underfitting.

- （每棵树的特征抽样比率）colsample_bytree: percentage of features used per tree. High value can lead to overfitting.

- （树的个数）n_estimators: number of trees you want to build.

- （损失函数选择）objective: determines the loss function to be used like reg:linear for regression problems, reg:logistic for classification problems with only decision, binary:logistic for classification problems with probability.

XGBoost also supports regularization parameters to penalize models as they become more complex and reduce them to simple (parsimonious) models.

惩罚函数参数：回顾下

\begin{equation}
\Omega(f)=\gamma T+\frac{1}{2} \lambda\|w\|^{2}
\end{equation}

gamma: controls whether a given node will split based on the expected reduction
in loss after the split. A higher value leads to fewer splits. Supported only
for tree-based learners. gamma 控制是否节点会分裂，如果 loss 下降的话，那么就会分
裂，否则不分裂。

alpha: L1 regularization on leaf weights. A large value leads to more regularization.

lambda: L2 regularization on leaf weights and is smoother than L1 regularization.

具体可以见 https://www.datacamp.com/community/tutorials/xgboost-in-python.

我们可以从 importance 知道变量的重要性，但是这些因素之间的是否是正相关，还是负相关还是其他更复杂的相关性，我们无法得知，也无法解读每个特征对每个个体的预测值的影响。

可以利用 shap value 对 xgboost 模型进行解释。

啥叫 shap value?

可以参考以下连接：http://sofasofa.io/tutorials/shap_xgboost/

总结 XGBoost 算法流程，基于决策树弱分类器。

输入：是训练集样本 $I={(x_{1},y_{1}),(x_{2},y_{2}),\cdots,(x_{m},y_{m})}$, 最大迭代次数 $T$, 损失函数 $L$, 正则化系数 $\lambda,\gamma$.
输出：强学习器

https://pic4.zhimg.com/v2-f8e7906c5ef33b2c737d30893de182eb_b.jpg






**** lightgbm
LightGBM 使用的是 leaf-wise 策略（也就是叶优先策略），而 XGB 和 GBM 都是使用 level-wise 策略。leaf-wise 更优，这也是 LightGBM 的主要改进。

**** GBDT
参数估计方法：GBDT 在函数空间中利用梯度下降法进行优化。

估计流程：
输入：\(\left(x_{i}, y_{i}\right), T, L\) ,即 data,基分类器个数（迭代次数），损失函数类型。

1.初始化 $f_{0}$
2.for t=1 to T do
2.1 计算响应：\(\widetilde{y_{i}}=-\left[\frac{\partial L\left(y_{i}, F\left(x_{i}\right)\right)}{\partial F\left(x_{i}\right)}\right]_{F(x)=F_{t-1}(x)}, i=1,2, \ldots N\)

2.2 学习第 t 颗树：\(w^{*}=\underset{w}{\arg \min } \sum_{i=1}^{N}\left(\tilde{y}_{i}-h_{t}\left(x_{i} ; w\right)\right)^{2}\)

2.3 line search 找步长：\(\rho^{*}=\underset{\rho}{\arg \min } \sum_{i=1}^{N} L\left(y_{i}, F_{t-1}\left(x_{i}\right)+\rho h_{t}\left(x_{i} ; w^{*}\right)\right)\)

2.4 令 \(f_{t}=\rho^{*} h_{t}\left(x ; w^{*}\right)\), 更新模型：\(F_{t}=F_{t-1}+f_{t}\)

3.输出 $F_{T}$.

#+begin_src python
from sklearn.datasets import make_classification
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.model_selection import train_test_split
X, y = make_classification(random_state=0)
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)
clf = GradientBoostingClassifier(random_state=0, learning_rate = 0.1, n_estimators = 150, loss = "exponential", subsample=0.5,)
clf.fit(X_train, y_train)
clf.predict(X_test[:2])
clf.score(X_test, y_test)
#+end_src

上面 code 里有 n_estimators 是 基学习器个数，learning_rate 是梯度下降的步长，
loss 是损失函数，subsample 即在拟合一棵新的回归树时，不用完全的样本集，而仅是无放回的抽样其中的部分，通常为 50%，对于大的数据集，抽样的比例可以小于 50%。subsampling 的方式可以避免过拟合，同样地，更小的训练集也可以更快的完成训练。

*** Bagging
Bagging is purely a variance-reduction technique, and since trees tend to have high variance, bagging often produces good results.

这解释了为啥 Bagging 为啥得到的估计大幅压缩方差，因为树的方差较大。

Bagging 对样本重抽样，对每一重采样得到的子样本集训练一个模型，最后取平均。由于子样本集合的相似性以及使用的是同一种模型，因此各个模型有近似相等的 bias 和 variance (事实上，各模型的分布也近似相同，但是不独立).
若各个子模型独立，那么肯定会显著降低方差（variance），若各个子模型完全相同，那么不会降低模型方差。bagging 方法得到的各子模型是有一定相关性，属于上面 2 个极端状况的中间态，因此可以在一定程度上降低 variance.

所以说，bagging 方法主要是通过降低模型方差提升预测精度，boosting 主要利用 sequential 地最小化损失函数，其 bias 自然逐步下降，所以 boosting 主要靠降低 bias 来提升预测精度。

能不能将 random forest 方法与 adaboost 方法进行结合？

#+begin_src python
from sklearn.ensemble import BaggingClassifier
from sklearn.tree import DecisionTreeClassifier
bag_clf = BaggingClassifier(

)
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
X, y = load_iris(return_X_y=True)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import BaggingClassifier
from sklearn.tree import DecisionTreeClassifier
bag_clf = BaggingClassifier(DecisionTreeClassifier(),
                            n_estimators=500,max_samples=100,bootstrap=True,n_jobs=-1)
bag_clf.fit(X_train, y_train)
y_pred = bag_clf.predict(X_test)
y_pred
#+end_src

** CNN(convolutional neural network)

卷积神经网络，利用卷积运算对图片进行特征提取，再经过 Relu, pooling 等过程进一步实现图像信息的有效提取，从而达到图片特征信息提取的作用，最后经过全连接也就是通常所
说的 NN 中的 softmax 算法实现对图片分类目的。

深度学习模型是一种表示学习（representation learning），能够学到数据更高层次的抽象表示，能够自动从数据中提取特征。

一个简单的卷积神经网络是由各种层按照顺序排列组成，网络中的每一层使用一个可微分的函数将数据从一层传递到下一层，卷积神经网络主要由三种类型的层构成：卷积层，池化层
和全连接层。

卷积是一种线性的\平移不变性的运算。

1.卷积：首先需要有 feature,也就是卷积核（filter，一般是 3*3,5*5 大小）（问题：如何找到这卷积核？从训练集中提取，如果是找人，那么一定有鼻子\眼睛\嘴），然后与目标
图片作卷积运算。

2.Relu 层（非线性激活层）。卷积后产生的特征图中的值，越靠近 1 表示与该特征越关联，越靠近-1 表示越不关联，而我们进行特征提取时，为了使得数据更少，操作更方便，就直接舍弃掉那些不相关联的数据。

3.pooling 池化层。进一步缩减图片大小。

*** Resnet

    深度残差网络（deep residual network, Resnet）。深度学习模型很难训练，存在梯度消失或爆炸问题。batchnorm 可以解决这个问题。

一种方法的提出，首先需要问“这个方法解决了什么问题？”

ResNet 解决了深度 CNN 模型难训练的问题。如何解决？

*** RNN (循环神经网络)

    通常意义上的神经网络都只能单独的取处理一个个的输入，前一个输入和后一个输入是完全没有关系。但是，某些任务需要能够更好的处理序列的信息，即前面的输入和后面的输入的有关系的。

RNN 与 CNN 的关键区别在于，它是一个序列的神经网络，即前一

https://pic4.zhimg.com/80/v2-28d17fdfecc6f6353666fc97cb09b1df_720w.jpg

一般认为，RNN 结构由输入层、隐藏层、输出层构成。

https://pic4.zhimg.com/80/v2-3884f344d71e92d70ec3c44d2795141f_1440w.jpg

我们现在这样来理解，如果把上面有 W 的那个带箭头的圈去掉，它就变成了最普通的全连接神经网络。

x 是一个向量，它表示输入层的值（这里面没有画出来表示神经元节点的圆圈）；s是一个向量，它表示隐藏层的值（这里隐藏层面画了一个节点，你也可以想象这一层其实是多个节点，节点数与向量 s 的维度相同）；

U 是输入层到隐藏层的权重矩阵，o也是一个向量，它表示输出层的值；V是隐藏层到输出层的权重矩阵。

那么，现在我们来看看 W 是什么。循环神经网络的隐藏层的值 s 不仅仅取决于当前这次的输入 x，还取决于上一次隐藏层的值 s。权重矩阵 W 就是隐藏层上一次的值作为这一次的输入的权重。

其中，这个就有点像时间序列的意思。

https://pic1.zhimg.com/80/v2-206db7ba9d32a80ff56b6cc988a62440_1440w.jpg

从上图可以很清晰地看出，上一时刻的隐藏层是如何影响当前时刻的隐藏层。

用公式表示如下：

\[
O_{t} = g(V \dot S_{t})

S_{t} = f(U \dot X_{t} + W \dot S_{t-1})
\]

$S_{t}$ 的值不仅仅取决于 $X_{t}$, 还取决于 $S_{t-1}$.
*** LSTM

长短期记忆（long short-term memory,lstm） 是一种特殊的 RNN, 主要是为了解决长序列训练过程中的梯度消失和梯度爆炸问题。简单来说，就是相比普通的 RNN，LSTM 能够在更长的序列中有更好的表现。

https://pic4.zhimg.com/80/v2-e4f9851cad426dfe4ab1c76209546827_720w.jpg

相比 RNN 只有一个传递状态 $h^{t}$, LSTM 有 2 个传递状态，一个 $c^{t}$(cell state),和一个 $h^{t}$(hidden state).

其中，对于传递下去的 $c^{t}$ 改变得很慢，通常输出的 $c^{t}$ 是上一个状态传过来的 $c^{t-1}$ 加上一些数值。而 $h^{t}$ 则在不同节点下往往会有很大的区别。

RNN 中的 $h^{t}$ 对于 LSTM 中的 $c^{t}$.

简单地说，LSTM 内部主要有三个阶段：

1.忘记阶段。这个阶段主要是对上一个节点传进来的输入进行选择性忘记。简单来说就是会“忘记不重要的，记住重要的”。具体来说是通过计算得到的 $z^{f}$ 来作为忘记门控，来控制上一个
状态的 $c^{t-1}$ 哪些需要留哪些需要忘。

2.选择记忆阶段。这个阶段将这个阶段的输入有选择性进行“记忆”。主要是会对输入 $x^{t}$ 进行选择记忆。哪些重要则着重记录下来，哪些不重要，则少记一些。当前的输入内容由前面计算得到的 $z$ 表示，而选择的门控信号则是由 $z^{i}$ 来控制。

将上面两步得到的结果相加，即可得到传输给下一个状态的 $c^{t}$.

3.输出阶段。这个阶段将决定哪些将会被当成当前状态的输出。主要是通过 $z^{o}$ 来进行控制的，并且还对上一阶段得到的 $c^{o}$ 进行了防缩（通过一个 tanh 激活函数进行变化）。

*** HMM
啥叫隐马尔可夫模型？
隐马尔可夫模型，一定存在马尔可夫链，该马尔可夫链服从马尔可夫性质：无记忆性。也就是说，这一时刻的状态，受且只受前一时刻的影响，而不受更前往时刻的状态的影响。

在这个马尔可夫模型中，存在三个状态，sunny,rainy,cloudy,既是隐形，说明这些状态是观测不到的，相应的，我们可以通过其他方式来“猜测” 或 “推断” 这些状态，这也是 HMM 需要解决的问题。

example:

举个例子，我女朋友现在在北京工作，而我还在法国读书。每天下班之后，她会根据天气情况有相应的活动：或是去商场购物，或是去公园散步，或是回家收拾房间。我们有时候会通电话，她会告诉我她这几天做了什么，而闲着没事的我呢，则要通过她的行为猜测这几天对应的天气最有可能是什么样子的。

以上就是一个简单的 HMM，天气状况属于状态序列，而她的行为则属于观测序列。天气状况的转换是一个马尔可夫序列。而根据天气的不同，有相对应的概率产生不同的行为。在这里，为了简化，把天气情况简单归结为晴天和雨天两种情况。雨天，她选择去散步，购物，收拾的概率分别是 0.1，0.4，0.5，而如果是晴天，她选择去散步，购物，收拾的概率分别是 0.6，0.3，0.1。而天气的转换情况如下：这一天下雨，则下一天依然下雨的概率是 0.7，而转换成晴天的概率是 0.3；这一天是晴天，则下一天依然是晴天的概率是 0.6，而转换成雨天的概率是 0.4. 同时还存在一个初始概率，也就是第一天下雨的概率是 0.6， 晴天的概率是 0.4.

根据以上的信息，我们得到了 HMM 的一些基本要素：初始概率分布 $\pi$ ，状态转移矩阵 A，观测量的概率分布 B，同时有两个状态，三种可能的观测值。

现在，重点是要了解并解决 HMM 的三个问题。

问题 1，已知整个模型，我女朋友告诉我，连续三天，她下班后做的事情分别是：散步，购物，收拾。那么，根据模型，计算产生这些行为的概率是多少。

问题 2，同样知晓这个模型，同样是这三件事，我女朋友要我猜，这三天她下班后北京的天气是怎么样的。这三天怎么样的天气才最有可能让她做这样的事情。

问题 3，最复杂的，我女朋友只告诉我这三天她分别做了这三件事，而其他什么信息我都没有。她要我建立一个模型，晴雨转换概率，第一天天气情况的概率分布，根据天气情况她选择做某事的概率分布。（惨绝人寰）

问题 1 的解决 1：遍历算法。要计算产生这一系列行为的概率，那我们把每一种天气情况下产生这些行为都罗列出来，那每种情况的和就是这个概率。有三天，每天有两种可能的天气情况，则总共有 2 的三次=8 种 情况.

举例其中一种情况：
 P（下雨，下雨，下雨，散步，购物，收拾）=P（第一天下雨）P（第一天下雨去散步）P（第二天接着下雨）P（下雨去购物）P（第三天还下雨）P（下雨回家收拾）=0.6X0.1X0.7X0.4X0.7X0.5=0.00588 当然，这里面的 P（第二天接着下雨）当然是已知第一天下雨的情况下，第二天下雨的概率，为 0.7.将八种情况相加可得，三天的行为为{散步，购物，收拾}的可能性为 0.033612. 看似简单易计算，但是一旦观察序列变长，计算量就会非常庞大（的复杂度，T 为观测序列的长度）。





** 迁移学习
** 因子分解机

一般会用“线性模型 + 人工特征组合” 引入非线性的模式训练 LR 模型。 一般会用人工方法对特征进行筛选，但是因子分解机也可以自动化地组合筛选交叉特征。

因子分解机在这里的优势在于当遇到大规模稀疏特征时，模型的泛化能力也减弱，原因在于此时，满足交叉项不为 0 的样本将非常少，当训练样本不足时，很容易导致参数训练不充分而不准确，最终影响模型的效果。但是因子分解机也可以很好地解决这个问题，通过将交叉特征系数做分解，让不同的交叉项之间不再独立，因此一个交叉项的数据可以辅助来估计另一个交叉项，这样做的好处在于可以让估计系数远远小于直接在线性模型中整合二阶交叉特征。

这里的分解机的参数个数为 1+n+kn, 而整合后的二阶交叉的线性模型的系数个数为 $1+n+n^2$. 所以，看出当 n 非常大时，训练分解机模型在存储空间及迭代速度上是非常有优势的。

** 不平衡数据分类算法
*** SMOTE

** 10 主题学习
*** 联邦学习

根据建模参与方之间的数据分布不同，把联邦学习分为三类：横向联邦学习，纵向联邦学习、联邦迁移学习。

横向联邦学习：特征重叠多，用户重叠少，可以进行样本联合，横向联邦学习适用于参与者业态相同但触达客户不同，即特征重叠多，用户重叠少时的场景，比如不同地区的银行间，他们的业务相似，但用户不同（样本不同）。

步骤：

1.参与方各自从服务器 A 下载最新模型；

2.每个参与方利用本地数据训练模型，加密梯度上传给服务器 A，服务器 A 聚合各用户的梯度更新模型参数；

3. 服务器 A 返回更新后的模型给各参与方；

4.各参与方更新各自模型。

*** 拒绝推断

1.重新分类法

重新分类的核心思想对被拒绝用户做好坏属性的重新划分，比如，当一个被拒绝的申请者具有一些负面特征，比如通过人行征信，我们发现其在过去 3 个月内有逾期行为，则可以把他划分成坏人。

问题：利用第三方数据对拒绝样本进行标注，这些数据只能标注一部分黑样本，白样本很难标注，而且黑的定义和本网贷平台的黑的定义（是否逾期）之间也有黑的差异性。

2.分散打包法

分散打包是指根据前面的“状态值”给被拒绝用户一个随机的好坏状态，假设好人概率 $P(G) = 0.9$, 那么使得被拒绝用户的好人概率是 0.9， 坏人概率是 0.1.还有一种处理方法是在“状态值”上设定一个临界值，使得大于该值的为好人，反之为坏人。

3.重新加权法

重新加权法没有将被拒绝用户加入到样本中，而是将样本中现存的处于相同“状态值”分数段的好坏借款人的权重同步增加，增加幅度是分数段中被拒绝用户的数量。

举例，假设某分数段中有 90 个好人，10 个坏人和 50 个被拒绝用户，每个好坏借款人都被赋予 150/100=1.5 的权重，所以看起来好像该组有 135 个好人和 15 个坏人。

4.展开法

在展开法中，我们试图计算“状态值”，这里的状态值通常指好人概率。我们先假设存在一个统计量 $Z$, 有相同 $Z$ 值的被拒绝用户和授信用户的好人概率相同。数学上表示如下：

\[
p(G|R,z) = p(G|A,z)
\]

这里，A = accept，表示授信用户组，R = reject 表示被拒绝用户组；我们可以建立“授信/拒绝”评分卡来区分样本中谁被接受谁被拒绝。Z 是这个评分卡的分数。为了更符合实际，我们假定被拒绝用户组中的好人比例小于授信用户的好人比例，且随 z 变动，即

\[
P(G|R,z) = k(z)*P(G|A,z), k(z) <1
\]

得到被拒绝用户的好人概率后，我们就可以使用分散打包法或重新加权法来增加样本容量了。

5.外推法

外推法的依据是存在一些特征 $X$, 在授信用户和被拒绝用户之间没有任何重叠。然后我们构造函数 $g$, 使其将好人概率 $P(G)$ 和 $x$ 关联起来。设授信用户的区域为 XA，被拒绝用户的区域为 XR，则函数 g 可表示为：

\[
g(x) = P(G|A,x) = P(G|x), x\in X_{A}
\]

接下来，我们将这个函数外推为 $g~$,有

\[
g_{~}(x) = P(G|R,x) = P(G|x), x\in X_{R}
\]

以上各种拒绝推断方法，都是对每个或者部分已拒绝的申请者给出好坏状态值，增加样本总体的大小，从而减少参数估计偏差，从而减小参数估计偏差。

但是，以上方法都是一定程度上假设好人概率 $P(G)$ 在授信用户和被拒绝用户之间的关系，这种假设存在的最大问题是被拒绝用户并非是“随机缺失” （missing not at random,mnr），而是因为在某个或某些维度上体现出了坏人的属性。

因此，如不随机放一些被拒绝用户进来，则无法被实践检验。而如果实践中，我们随机放一些拒绝用户进来，可以想象，必然会造成一笔不小的损失（例如，放进来一批学历低&失业&多头借贷用户）。


经典的拒绝推断方法从广义上可分为 2 大类：数据法（data methods）和推断法（inference methods）。

数据法：获取拒绝样本的其它表现数据。

- 接受本该拒绝（reject acceptance）

- 同生表现（cohort performance），又称为重新分类法

- 拒绝原因。（这是啥意思？）

推断法：推断拒绝和放贷样本之间的差异，进而调整建模样本组成来构建模型。

- 展开法：又称为重新加权法

- 打包法：又称为外推法

- 迭代再分类法

- 两阶段法（又称为双变量推断法）








** 变量选择

- 绕封法：不断增加或删除预测变量，通过评估包含不同变量的模型找到最优的变量组合。
  比如：向前，向后，逐步选择方法，模拟退火法，遗传算法。逐步选择法是向前选择法的一个变体：每在模型中加
  入一个新的变量，重新评估选中的每个变量并移除没有达到标准的变量。在某些情况，选
  入和删除变量使用的 P 值阈值可以不同。模拟退火法的思想是：选择一个初始预测变量
  子集，然后估计模型表现（将$E_{1}$ 记为初始莫模型错误率，稍稍改变当前的预测变量
  子集后重建模型，且计算新的错误率，记为$E_{2}$,若新模型优于老模型，即
  $E_{2}<E_{1}$,则新的变量集合就被接受。）

- 过滤法：在建模前先独立于模型评估预测变量和结果变量的相关性，然后在建模时只包含
  那些满足一定条件的变量。过滤法跟建模过程本身没有关系。
** 算法
*** EM 算法
最大期望算法（Expectation-maximization algorithm，又译为期望最大化算法），是在概率模型中寻找参数最大似然估计或者最大后验估计的算法，其中概率模型依赖于无法观测的隐性变量。最大期望算法经过两个步骤交替进行计算：

1. 计算期望（E），利用对隐藏变量的现有估计值，计算其最大似然估计值；
2. 最大化（M），最大化在 E 步上求得的最大似然值来计算参数的值。M步上找到的参数估计值被用于下一个 E 步计算中，这个过程不断交替进行。

**** 为何需要 EM 算法？
 含有隐变量 $Z$ 的模型比如混合高斯模型，

 \begin{equation}
 P(X ; \theta)=\sum_{k=1}^{K} \pi_{k} N\left(x ; \mu_{k}, \sigma_{k}\right)=\sum_{Z} P(Z ; \pi) P(X | Z ; \mu, \sigma)
 \end{equation}

 上面假设共有 $K$ 个高斯模型混合，每个高斯模型的参数为 $\theta_{k}=\left(\mu_{k},
 \sigma_{k}\right)$,每个高斯模型占总模型的比重为 $\pi_{k}$. 隐变量 $Z
 \in\left\{z_{1}, z_{2}, \ldots, z_{K}\right\}$ 表示样本 $x_{i}$ 来自于哪一个高斯
 分布。分布列为：

 \begin{equation}
 \begin{array}{l}{\mathrm{P}\left(\mathrm{Z}=z_{1}\right)=\pi_{1}} \\ {\cdots} \\ {\mathrm{P}\left(\mathrm{Z}=z_{K}\right)=\pi_{K}}\end{array}
 \end{equation}

 可以认为，混合高斯分布的观测值是这样产生的：

 先以概率 $\pi_{k}$ 抽取一个高斯分布 $z_{k}$,再以该高斯分布 \(N\left(x ; \mu_{k},
 \sigma_{k}\right)\) 去生成观测 $X$. 其实这里的 $\pi_{k}$ 就是 $\pi_{k}$ 就是 $Z$
 的先验分布 \(P(Z ; \pi)\),而 \(N\left(x ; \mu_{k}, \sigma_{k}\right)\) 就是给定
 $Z$ 下的条件概率 \(P(X | Z ; \mu, \sigma)\).这时，令 \(\theta=(\mu, \sigma,
 \pi), \theta^{*}=\left(\mu^{*}, \sigma^{*}, \pi^{*}\right)\),最大似然估计变为：

 \begin{equation}
 \begin{aligned} \theta^{*} &=\arg \max _{\theta} \sum_{X} \log P(X ; \theta) \\ &=\arg \max _{\theta} \sum_{X} \log \sum_{Z} P(Z ; \pi) P(X | Z ; \mu, \sigma) \\ &=\arg \max _{\theta} \sum_{X} \log \sum_{Z} P(X, Z ; \theta) \end{aligned}
 \end{equation}

 上式求解$\theta$ 偏导有些许麻烦，所以就有了 EM 算法。

 总结：

 EM 算法是针对传统似然含有未知数据或者缺失数据时，它的似然估计求导较为困难而提出
 的。
**** E 步和 M 步

为了让上式中的 log 函数进入到 $\sum_{Z}$ 中从而可以直接对最里层的式子求偏导。所
以 E 步的作用就是想让 log 函数进入到 $\sum_{Z}$. 为了解决这个问题，可以使用 Jensen
不等式，因为 log 是个凹函数，以隐变量 $Z$ 的任一函数 $f(Z)$ 举例：\(\log E[f(Z)]=\log \sum_{Z} P(Z) f(Z) \geq \sum_{Z} P(Z) \log f(Z)=E[\log f(Z)]\).

根据 jensen 不等式的性质，当随机变量函数 $f(Z)$ 为常数时，不等式可取等式。上式中
的期望换成条件期望，分布 $P(Z)$ 换成条件分布同样适用。

\begin{equation}
\begin{aligned} \operatorname{Max} &=\max _{\theta} \sum_{X} \log \sum_{Z} P(X, Z ; \theta) \\ &=\max _{\theta} \sum_{X} \log \sum_{Z} Q(Z ; \theta) \cdot \frac{P(X, Z ; \theta)}{Q(Z ; \theta)} \\ &=\max _{\theta} \sum_{X} \log E_{Q}\left[\frac{P(X, Z ; \theta)}{P(Z ; \theta)}\right] \\ & \geq \max _{\theta} \sum_{X} E_{Q}\left[\log \frac{P(X, Z ; \theta)}{Q(Z ; \theta)}\right] \\ &=\max _{\theta} \sum_{X} \sum_{Z} Q(Z ; \theta) \log \frac{P(X, Z ; \theta)}{Q(Z ; \theta)} \end{aligned}
\end{equation}

上式中 $Q(Z)$ 还是 $Z$ 的随机变量函数，只有当 \(\frac{P(X, Z ; \theta)}{Q(Z ;
\theta)}=c\) (c 为任意常数),上公式才能取等号，注意到 $Q$ 是 $Z$ 的某一分布，有
\(\sum_{Z} Q(Z ; \theta)=1\). 因此，

\begin{equation}
\begin{aligned} Q(Z ; \theta) &=\frac{P(X, Z ; \theta)}{c}=\frac{P(X, Z ; \theta)}{c \cdot \sum_{Z} Q(Z ; \theta)} \\ &=\frac{P(X, Z ; \theta)}{\sum_{Z} c \cdot Q(Z ; \theta)}=\frac{P(X, Z ; \theta)}{\sum_{Z} P(X, Z ; \theta)} \\ &=\frac{P(X, Z ; \theta)}{P(X ; \theta)}=P(Z | X ; \theta) \end{aligned}
\end{equation}

所以，只需要把 $Q$ 取给定 $X$ 下， $Z$ 的后验分布，就能使使之前的公式取等号，下
一步只需要最大化即可。

这时，\(\theta^{*}=\arg \max _{\theta} \sum_{X} \sum_{Z} P(Z | X ; \theta) \log \frac{P(X, Z ; \theta)}{P(Z | X ; \theta)}\).

其中：\(P(X, Z ; \theta)=P(Z ; \pi) P(X | Z ; \mu, \sigma)=\pi_{k} N\left(x_{i} ; \mu_{k}, \sigma_{k}\right)\),\(P(Z | X ; \theta)=\frac{P(X, Z ; \theta)}{\sum_{Z} P(X, Z ; \theta)}=\frac{\pi_{k} N\left(x_{i} ; \mu_{k}, \sigma_{k}\right)}{\sum_{k=1}^{K} \pi_{k} N\left(x_{i} ; \mu_{k}, \sigma_{k}\right)}\).

直接对 \((\mu, \sigma, \pi)\) 求导还是很麻烦，不过已经可以用迭代来最大化。迭代的步骤如下。

1）根据上公式，由 \(\left(\mu^{(j)}, \sigma^{(j)}, \pi^{(j)}\right)\) 求解后验分布
\(Q^{(j)}=P\left(Z | X ; \theta^{(j)}\right)\).

2）再把 $Q^{(j)}$ 代入上公式中，

\begin{equation}
\begin{aligned} \theta^{(j+1)} &=\arg \max _{\theta} \sum_{X} \sum_{Z} Q^{(j)} \log \frac{P(X, Z ; \theta)}{Q^{(j)}} \\ &=\arg \max _{\theta} \sum_{X} \sum_{Z}\left(Q^{(j)} \log P(X, Z ; \theta)-Q^{(j)} \log Q^{(j)}\right) \\ &=\arg \max _{\theta} \sum_{X} \sum_{Z} Q^{(j)} \log P(X, Z ; \theta) \end{aligned}
\end{equation}

这就只需要最大化联合分布 \(P(X, Z ; \theta)\) 了，最大化求出
\(\left(\mu^{(j+1)}, \sigma^{(j+1)}, \pi^{(j+1)}\right)\) 后再重复这 2 步。

M 步很显然，就是最大化那一步，E 步是那一步呢？根据上一公式有，

\begin{equation}
\begin{aligned} \theta^{(j+1)} &=\arg \max _{\theta} \sum_{X} \sum_{Z} Q^{(j)} \log P(X, Z ; \theta) \\ &=\arg \max _{\theta} \sum_{X} E_{Q^{(j)}}[\log P(X, Z ; \theta)] \\ &=\arg \max _{\theta} \sum_{X} E_{Z | X ; \theta^{(j)}}[\log P(X, Z ; \theta)] \\ &=\arg \max _{\theta} \sum_{X} E_{Z}\left[\log P(X, Z ; \theta) | X ; \theta^{(j)}\right] \end{aligned}
\end{equation}

其实，E 步就是求给定 $X$ 下的条件期望，也就是后验期望，使得 jenson 不等式能够取等号，是对 Jenson 不等式中小的那一端进行放大，使其等于大的那一端，这是一次放大；M步最大化联合分布，通过 0 梯度，拉格朗日等方法求极值点，又是一次放大。只要似然函数是有界的，只要 M 步中的 0 梯度点是极大值点，一直放大下去就能找到最终所求了。

总结下，EM 算法思想:

Deﬁne the complete data log likelihood to be

$$
\ell_{c}(\boldsymbol{\theta}) \triangleq \sum_{i=1}^{N} \log
p\left(\mathbf{x}_{i}, \mathbf{z}_{i} | \boldsymbol{\theta}\right)
$$

This cannot be computed,since $\mathbf{z}_{i}$ is unknown.So let us define the *expected complete data log likelihood* as follows:

\begin{equation}
Q\left(\boldsymbol{\theta}, \boldsymbol{\theta}^{t-1}\right)=\mathbb{E}\left[\ell_{c}(\boldsymbol{\theta}) | \mathcal{D}, \boldsymbol{\theta}^{t-1}\right]
\end{equation}

where $t$ is the current iteration number. $Q$ is called the auxiliary function.The expectation is taken wrt the old parameters, $\theta^{t-1}$,and the observed data $\mathcal{D}$.The goal of the *E step* is to complete
$Q\left(\boldsymbol{\theta}, \boldsymbol{\theta}^{t-1}\right)$,or rather, the
terms inside of it which the MLE depends on;these are known as the *expected
sufficient statistics* or ESS. In the *M step*,we optimize the Q function wrt $\boldsymbol{\theta}$:
$$
\boldsymbol{\theta}^{t}=\arg \max _{\boldsymbol{\theta}} Q\left(\boldsymbol{\theta}, \boldsymbol{\theta}^{t-1}\right)
$$

再次总结：
1.先估计隐变量 z 的分布，然后利用 Z 的分布去估计目标参数的概率值。

辅助资料：https://www.jianshu.com/p/1121509ac1dc ; https://www.zhihu.com/question/27976634


* References

 bibliographystyle:natbib
 bibliography:~/Documents/坚果云/我的坚果云/学习/bibliography/ref.bib

* 统计
:PROPERTIES:
:NOTER_DOCUMENT: 统计.pdf
:END:

所以什么是因子分解机？
